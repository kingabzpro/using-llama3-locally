# using-llama3-locally
Running llama3 using Ollama-Python, Curl, LangChain, User interface, GPT4ALL
